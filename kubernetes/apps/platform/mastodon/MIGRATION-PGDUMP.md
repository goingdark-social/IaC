# Migrating Zalando Postgres Operator to CloudNativePG Using pg_dump

This document describes the production migration strategy for moving the Mastodon PostgreSQL database from Zalando Postgres Operator to CloudNativePG using logical backups (pg_dump/pg_restore). This approach is preferred for production environments as it provides fine-grained control, repeatability, and operates without blocking production traffic during the initial import.

## Why pg_dump/pg_restore?

**Non-blocking exports**: pg_dump creates consistent exports without blocking readers or writers. You can take the initial backup while the production application continues to operate.

**Portable logical backups**: Dumps can be restored on any PostgreSQL version supported by CloudNativePG. pg_dump produces a custom-format archive that can be restored in parallel for speed.

**Fine-grained control**: CloudNativePG's import feature exposes `pgDumpExtraOptions` and `pgRestoreExtraOptions` fields, allowing you to tune the commands for optimal performance.

**Proven safety**: Logical backups are well-tested and provide clear verification points before and after migration.

## Migration Strategy Overview

This migration uses CloudNativePG's built-in `bootstrap.initdb.import` feature to automatically:
1. Run pg_dump against the source Zalando cluster
2. Transfer the dump to the new cluster
3. Restore it using pg_restore with parallel jobs

The process has two phases:

### Phase 1: Initial Import (Zero Downtime)
- Deploy CloudNativePG cluster with import configuration
- CNPG automatically runs pg_dump from the Zalando cluster
- Production continues running on Zalando cluster
- Verify import completed successfully

### Phase 2: Final Cutover (Short Maintenance Window)
- Scale down Mastodon workloads (planned maintenance)
- Take final incremental dump of any changes (optional, for safety)
- Switch application to CloudNativePG cluster
- Verify and scale up workloads
- Resume production

## Prerequisites

- [x] CloudNativePG operator installed (`kubernetes/apps/database/cloudnative-pg/`)
- [x] Zalando Postgres Operator cluster running (`mastodon-postgresql`)
- [x] ExternalSecret configured for standby credentials (`zalando-standby-credentials`)
- [x] TLS certificates configured (`mastodon-postgresql-ca`, `mastodon-postgresql-server`)
- [x] kubectl and kubectl-cnpg plugin installed
- [ ] Maintenance window scheduled (estimated 15-30 minutes)
- [ ] Backup of Zalando cluster verified and tested

## Pre-Migration Verification

### 1. Verify Standby User Credentials

The ExternalSecret automatically syncs the standby user credentials from the Zalando cluster:

```bash
# Verify the ExternalSecret is healthy
kubectl get externalsecret zalando-standby-credentials -n mastodon

# Check the generated secret exists
kubectl get secret zalando-standby-credentials -n mastodon

# Verify the credentials (optional)
kubectl get secret zalando-standby-credentials -n mastodon \
  -o jsonpath='{.data.username}' | base64 -d
echo
kubectl get secret zalando-standby-credentials -n mastodon \
  -o jsonpath='{.data.password}' | base64 -d
echo
```

Expected output:
- Username: `standby`
- Password: (auto-generated by Zalando operator)

### 2. Test Connection from CloudNativePG Namespace

Before deploying, verify network connectivity and credentials:

```bash
# Create a test pod to verify connectivity
kubectl run -n mastodon pg-test --rm -it --restart=Never \
  --image=ghcr.io/cloudnative-pg/postgresql:17.5 \
  --env="PGHOST=mastodon-postgresql.mastodon.svc.cluster.local" \
  --env="PGPORT=5432" \
  --env="PGDATABASE=mastodon" \
  --env="PGUSER=standby" \
  --env="PGSSLMODE=verify-ca" \
  -- bash -c "
    echo \$PGPASSWORD | base64 -d > /tmp/pgpass
    export PGPASSWORD=\$(cat /tmp/pgpass)
    psql -c 'SELECT version();'
  "
```

### 3. Check Current Database Size

Estimate import time based on database size:

```bash
kubectl exec -n mastodon mastodon-postgresql-0 -- \
  psql -U postgres -c "
    SELECT 
      pg_database.datname,
      pg_size_pretty(pg_database_size(pg_database.datname)) AS size
    FROM pg_database
    WHERE datname = 'mastodon';
  "
```

**Import time estimates**:
- < 10 GB: 5-15 minutes
- 10-50 GB: 15-45 minutes
- 50-100 GB: 45-90 minutes
- > 100 GB: 1.5-3 hours

## Phase 1: Initial Import (Zero Downtime)

### Step 1: Deploy CloudNativePG Cluster

The cluster is configured in `kubernetes/apps/platform/mastodon/resources/workloads/database-cnpg.yaml` with:

```yaml
bootstrap:
  initdb:
    import:
      type: monolith
      databases:
        - mastodon
      roles:
        - mastodon
      source:
        externalCluster: zalando-cluster
      pgDumpExtraOptions:
        - "--verbose"
        - "--format=custom"
        - "--no-owner"
        - "--no-acl"
      pgRestoreExtraOptions:
        - "--verbose"
        - "--jobs=4"
        - "--no-owner"
        - "--no-acl"
```

Deploy the cluster:

```bash
# From repository root
kustomize build kubernetes/apps/platform/mastodon/resources/workloads | kubectl apply -f -

# Or with ArgoCD (if auto-sync is disabled)
kubectl apply -f kubernetes/apps/platform/mastodon/resources/workloads/database-cnpg.yaml
```

### Step 2: Monitor Import Progress

Watch the cluster initialization:

```bash
# Watch pod status
kubectl get pods -n mastodon -l cnpg.io/cluster=database-cnpg -w

# Check cluster status
kubectl cnpg status database-cnpg -n mastodon

# View import logs
kubectl logs -n mastodon -l cnpg.io/cluster=database-cnpg -f
```

The import process will:
1. Create the cluster pod(s)
2. Initialize the database with `initdb`
3. Run `pg_dump` against the Zalando cluster
4. Run `pg_restore --jobs=4` to restore in parallel
5. Mark cluster as ready

**Expected log entries**:
```
INFO: Importing cluster from external cluster "zalando-cluster"
INFO: Running pg_dump with options: --verbose --format=custom --no-owner --no-acl
INFO: Dump completed successfully
INFO: Running pg_restore with options: --verbose --jobs=4 --no-owner --no-acl
INFO: Restore completed successfully
INFO: Database cluster is ready
```

### Step 3: Verify Import Completed Successfully

```bash
# Check cluster is ready
kubectl cnpg status database-cnpg -n mastodon

# Verify database and roles exist
kubectl cnpg psql database-cnpg -n mastodon -- -c "\l"
kubectl cnpg psql database-cnpg -n mastodon -- -c "\du"

# Check table counts match source
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  SELECT schemaname, COUNT(*) as table_count
  FROM pg_tables
  WHERE schemaname = 'public'
  GROUP BY schemaname;
"

# Compare with Zalando cluster
kubectl exec -n mastodon mastodon-postgresql-0 -- \
  psql -U postgres mastodon -c "
    SELECT schemaname, COUNT(*) as table_count
    FROM pg_tables
    WHERE schemaname = 'public'
    GROUP BY schemaname;
  "
```

### Step 4: Verify Data Integrity

Run sample queries to verify data migrated correctly:

```bash
# Check Mastodon accounts table
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  SELECT COUNT(*) FROM accounts;
"

# Check statuses table
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  SELECT COUNT(*) FROM statuses;
"

# Verify recent data (compare with source)
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  SELECT MAX(created_at) FROM statuses;
"
```

## Phase 2: Final Cutover (Maintenance Window)

### Pre-Cutover Checklist

- [ ] Initial import completed successfully (Phase 1)
- [ ] Data integrity verified
- [ ] Maintenance window communicated to users
- [ ] Rollback plan prepared
- [ ] Backup of Zalando cluster completed and verified

### Step 1: Announce Maintenance Window

Post on Mastodon instance:
```
ðŸš§ Scheduled Maintenance

We'll be performing a database migration in 15 minutes. 
Expected downtime: 15-30 minutes
Timeline: [START_TIME] - [END_TIME] UTC

This will improve performance and reliability. Thanks for your patience!
```

### Step 2: Scale Down Mastodon Workloads

```bash
# Stop all Mastodon pods to prevent new writes
kubectl scale deployment -n mastodon \
  mastodon-web \
  mastodon-streaming \
  mastodon-sidekiq-default \
  mastodon-sidekiq-federation \
  mastodon-sidekiq-background \
  mastodon-sidekiq-scheduler \
  --replicas=0

# Verify all pods are terminated
kubectl get pods -n mastodon | grep mastodon
```

### Step 3: Take Final Delta Dump (Optional but Recommended)

Capture any data written between initial import and cutover:

```bash
# Get timestamp of initial import completion
IMPORT_TIMESTAMP=$(kubectl logs -n mastodon -l cnpg.io/cluster=database-cnpg \
  | grep "Restore completed" \
  | tail -1 \
  | awk '{print $1}')

# Take incremental dump of recent changes
kubectl exec -n mastodon mastodon-postgresql-0 -- \
  pg_dump -U standby -d mastodon \
  --format=custom \
  --file=/tmp/delta-dump.dump \
  --verbose

# Copy dump to local machine for safety
kubectl cp mastodon/mastodon-postgresql-0:/tmp/delta-dump.dump ./delta-dump.dump
```

**Note**: This step is optional as the initial import should be very recent. Include it if there was significant time between import and cutover.

### Step 4: Reconfigure CloudNativePG for Production

Remove the import configuration and enable production features:

```bash
# Apply the promoted configuration
kubectl apply -f kubernetes/apps/platform/mastodon/resources/workloads/database-cnpg-promoted.yaml

# Verify cluster is healthy
kubectl cnpg status database-cnpg -n mastodon
```

The promoted configuration includes:
- Increased instances to 2 (HA)
- S3 backups enabled (scheduled backups twice weekly)
- WAL archiving to S3
- Production-ready PostgreSQL parameters

### Step 5: Update Application Configuration

#### 5.1 Get New Database Credentials

CloudNativePG auto-generates application credentials:

```bash
# Extract credentials
NEW_USER=$(kubectl get secret database-cnpg-app -n mastodon -o jsonpath='{.data.username}' | base64 -d)
NEW_PASS=$(kubectl get secret database-cnpg-app -n mastodon -o jsonpath='{.data.password}' | base64 -d)
NEW_HOST="database-cnpg-pooler-rw.mastodon.svc.cluster.local"

echo "New Database Configuration:"
echo "  Host: $NEW_HOST"
echo "  User: $NEW_USER"
echo "  Pass: $NEW_PASS"
```

#### 5.2 Update Database Credentials Secret

Mastodon deployments use `envFrom` to load `mastodon-db-url` secret with `DB_USER` and `DB_PASS` keys:

```bash
kubectl create secret generic mastodon-db-url -n mastodon \
  --from-literal=DB_USER="$NEW_USER" \
  --from-literal=DB_PASS="$NEW_PASS" \
  --dry-run=client -o yaml | kubectl apply -f -
```

#### 5.3 Update Database Host Configuration

**Option A: Update ConfigMap directly (immediate)**

```bash
kubectl patch configmap mastodon-database -n mastodon --type merge -p '{
  "data": {
    "DB_HOST": "database-cnpg-pooler-rw.mastodon.svc.cluster.local",
    "DB_PORT": "5432"
  }
}'
```

**Option B: Update source file and sync (GitOps)**

```bash
# Edit the config file
sed -i 's/DB_HOST=.*/DB_HOST=database-cnpg-pooler-rw.mastodon.svc.cluster.local/' \
  kubernetes/apps/platform/mastodon/configs/mastodon-database.env

# Commit and push
git add kubernetes/apps/platform/mastodon/configs/mastodon-database.env
git commit -m "chore: switch database to CloudNativePG pooler"
git push

# Sync with ArgoCD (if not auto-syncing)
argocd app sync platform/mastodon
```

### Step 6: Database Post-Migration Tasks

#### 6.1 Refresh Collation Version

PostgreSQL 17 may have updated collations:

```bash
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  ALTER DATABASE mastodon REFRESH COLLATION VERSION;
"
```

#### 6.2 Update Statistics (Optional)

Help the query planner with fresh statistics:

```bash
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  ANALYZE VERBOSE;
"
```

#### 6.3 Verify Indexes and Constraints

```bash
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  SELECT schemaname, tablename, indexname
  FROM pg_indexes
  WHERE schemaname = 'public'
  ORDER BY tablename, indexname
  LIMIT 20;
"
```

### Step 7: Restore Mastodon Workloads

Start with minimal replicas and scale up gradually:

```bash
# Start with 1 replica each for initial verification
kubectl scale deployment -n mastodon \
  mastodon-web --replicas=1 \
  mastodon-streaming --replicas=1 \
  mastodon-sidekiq-default --replicas=1 \
  mastodon-sidekiq-federation --replicas=1 \
  mastodon-sidekiq-background --replicas=1 \
  mastodon-sidekiq-scheduler --replicas=1

# Wait for pods to be ready
kubectl wait --for=condition=ready pod \
  -l app.kubernetes.io/name=mastodon \
  -n mastodon \
  --timeout=300s
```

### Step 8: Verify Application Health

#### 8.1 Check Pod Logs

```bash
# Web server logs
kubectl logs -n mastodon -l app=mastodon-web --tail=50

# Sidekiq logs
kubectl logs -n mastodon -l app=mastodon-sidekiq-default --tail=50

# Look for successful database connections
kubectl logs -n mastodon -l app=mastodon-web | grep -i "database\|postgres\|connected"
```

#### 8.2 Test Database Connectivity

```bash
# From web pod
kubectl exec -n mastodon deploy/mastodon-web -- \
  psql "$DATABASE_URL" -c "SELECT version();"

# Check active connections
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  SELECT count(*), usename, application_name
  FROM pg_stat_activity
  WHERE datname = 'mastodon'
  GROUP BY usename, application_name;
"
```

#### 8.3 Functional Testing

- [ ] Load homepage: `https://goingdark.social`
- [ ] Login with existing account
- [ ] Post a new status
- [ ] View home timeline
- [ ] Check notifications
- [ ] Verify federation (check federated timeline)
- [ ] Test search functionality

### Step 9: Enable HPA and Scale to Normal Load

```bash
# Scale to normal production replicas
kubectl scale deployment -n mastodon \
  mastodon-web --replicas=2 \
  mastodon-streaming --replicas=2 \
  mastodon-sidekiq-default --replicas=2 \
  mastodon-sidekiq-federation --replicas=2

# Verify HPA is controlling replicas
kubectl get hpa -n mastodon
```

### Step 10: Monitor for 1-2 Hours

Watch for any issues:

```bash
# Monitor pod health
watch kubectl get pods -n mastodon

# Monitor database connections
watch "kubectl cnpg psql database-cnpg -n mastodon -- -c 'SELECT count(*) FROM pg_stat_activity WHERE datname = \'mastodon\';'"

# Check for errors in logs
kubectl logs -n mastodon -l app=mastodon-web --since=10m | grep -i error
kubectl logs -n mastodon -l cnpg.io/cluster=database-cnpg --since=10m | grep -i error
```

## Post-Migration (After 24-48 Hours Stable Operation)

### Step 1: Verify Backup System

```bash
# Check scheduled backup is configured
kubectl get schedulebackup -n mastodon

# Trigger manual backup to verify
kubectl cnpg backup database-cnpg -n mastodon

# Verify backup in S3
kubectl cnpg backup list database-cnpg -n mastodon
```

### Step 2: Remove Zalando Resources

#### 2.1 Update Kustomization

```bash
# Remove Zalando manifest reference
cat <<EOF > kubernetes/apps/platform/mastodon/resources/workloads/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
- database-cnpg.yaml  # Only CNPG now
- elastic-sts.yaml
- redis-statefulset.yaml
- sidekiq-default-deployment.yaml
- sidekiq-federation-deployment.yaml
- sidekiq-background-deployment.yaml
- sidekiq-scheduler-deployment.yaml
- streaming-deployment.yaml
- web-deployment.yaml
EOF

# Move promoted config to primary
mv kubernetes/apps/platform/mastodon/resources/workloads/database-cnpg-promoted.yaml \
   kubernetes/apps/platform/mastodon/resources/workloads/database-cnpg.yaml

# Commit changes
git add kubernetes/apps/platform/mastodon/resources/workloads/
git commit -m "chore: remove Zalando Postgres Operator resources after CNPG migration"
git push
```

#### 2.2 Archive Zalando Cluster (Optional)

```bash
# Scale down Zalando cluster (keep for 7 days as safety net)
kubectl patch postgresql mastodon-postgresql -n mastodon \
  --type merge \
  -p '{"spec":{"numberOfInstances":0}}'

# After 7 days, delete the Zalando cluster
kubectl delete postgresql mastodon-postgresql -n mastodon

# Remove Zalando operator if no other clusters exist
kubectl get postgresql --all-namespaces
# If empty:
kubectl delete -f kubernetes/apps/database/postgresql/
```

### Step 3: Update Documentation

- [ ] Update `README.md` to reference CloudNativePG
- [ ] Update architecture diagrams
- [ ] Document new backup procedures
- [ ] Update runbooks with new `kubectl cnpg` commands

## Rollback Procedure (If Issues Arise)

If problems occur during cutover:

### Immediate Rollback (Within Maintenance Window)

```bash
# 1. Scale down CNPG-connected workloads
kubectl scale deployment -n mastodon \
  mastodon-web mastodon-streaming mastodon-sidekiq-* \
  --replicas=0

# 2. Revert database configuration
kubectl patch configmap mastodon-database -n mastodon --type merge -p '{
  "data": {
    "DB_HOST": "mastodon-postgresql.mastodon.svc.cluster.local",
    "DB_PORT": "5432"
  }
}'

# 3. Restore original credentials (if changed)
kubectl get secret mastodon-db-url -n mastodon -o yaml > /tmp/cnpg-creds-backup.yaml
# Restore from backup or recreate with original values

# 4. Scale up with original config
kubectl scale deployment -n mastodon \
  mastodon-web --replicas=2 \
  mastodon-streaming --replicas=2 \
  mastodon-sidekiq-default --replicas=1 \
  mastodon-sidekiq-federation --replicas=1 \
  mastodon-sidekiq-background --replicas=1 \
  mastodon-sidekiq-scheduler --replicas=1

# 5. Verify application works with Zalando cluster
```

### Post-Analysis

After rollback:
1. Collect logs from CloudNativePG cluster
2. Review any errors encountered
3. Update migration plan based on findings
4. Schedule new maintenance window when issues resolved

## Troubleshooting

### Import Fails or Takes Too Long

**Symptoms**: pg_dump/pg_restore fails or hangs

**Solutions**:
```bash
# Check network connectivity
kubectl exec -n mastodon -it deploy/database-cnpg-1 -- \
  ping mastodon-postgresql.mastodon.svc.cluster.local

# Check credentials
kubectl get secret zalando-standby-credentials -n mastodon -o yaml

# Check source database health
kubectl exec -n mastodon mastodon-postgresql-0 -- \
  psql -U postgres -c "SELECT pg_is_in_recovery();"

# View detailed import logs
kubectl logs -n mastodon -l cnpg.io/cluster=database-cnpg --tail=200
```

### Application Cannot Connect to New Database

**Symptoms**: Connection errors in application logs

**Checklist**:
- [ ] ConfigMap updated with correct `DB_HOST`
- [ ] Secret contains correct `DB_USER` and `DB_PASS`
- [ ] Pooler pods are running: `kubectl get pods -n mastodon -l cnpg.io/poolerName=database-cnpg-pooler-rw`
- [ ] Network policies allow traffic
- [ ] TLS certificates are valid

**Debug commands**:
```bash
# Test connection from application pod
kubectl exec -n mastodon deploy/mastodon-web -- \
  psql "host=database-cnpg-pooler-rw.mastodon.svc.cluster.local port=5432 dbname=mastodon user=mastodon sslmode=require" \
  -c "SELECT version();"

# Check pooler logs
kubectl logs -n mastodon -l cnpg.io/poolerName=database-cnpg-pooler-rw

# Verify service endpoints
kubectl get endpoints -n mastodon database-cnpg-pooler-rw
```

### Performance Degradation After Migration

**Symptoms**: Slow queries, high latency

**Actions**:
```bash
# Update statistics
kubectl cnpg psql database-cnpg -n mastodon -- -c "ANALYZE VERBOSE;"

# Check for missing indexes
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  SELECT schemaname, tablename, indexname
  FROM pg_indexes
  WHERE schemaname = 'public'
  ORDER BY tablename;
"

# Review slow queries
kubectl cnpg psql database-cnpg -n mastodon -- -c "
  SELECT query, mean_exec_time, calls
  FROM pg_stat_statements
  ORDER BY mean_exec_time DESC
  LIMIT 10;
"

# Check connection pooling
kubectl get pooler -n mastodon database-cnpg-pooler-rw -o yaml
```

## Monitoring and Alerting

### Key Metrics to Watch

**During Import**:
- Cluster pod status and restarts
- Import log messages
- Network I/O between clusters
- Source database load

**After Cutover**:
- Application pod health
- Database connection count
- Query latency (p95, p99)
- Backup success rate
- Replication lag (if using replicas)

### VictoriaMetrics Queries

```promql
# Database connections
sum(cnpg_backends_total{namespace="mastodon"}) by (datname)

# Replication lag
cnpg_pg_replication_lag{namespace="mastodon"}

# Backup age
time() - cnpg_pg_backup_last_successful_time{namespace="mastodon"}

# Query rate
rate(cnpg_pg_stat_database_xact_commit{namespace="mastodon"}[5m])
```

## Success Criteria

Migration is considered successful when:

- [x] CloudNativePG cluster is healthy and running
- [x] All Mastodon tables and data migrated
- [x] Application pods are healthy and processing requests
- [x] Users can login, post, and federate normally
- [x] No database-related errors in logs
- [x] Automated backups are working
- [x] Performance metrics are normal or improved
- [x] No data loss confirmed via spot checks
- [x] 24+ hours of stable operation

## Timeline Summary

| Phase | Duration | Downtime |
|-------|----------|----------|
| Pre-migration verification | 30 min | No |
| Initial import (Phase 1) | 15-90 min* | No |
| Maintenance window prep | 15 min | No |
| Cutover (Phase 2) | 15-30 min | Yes |
| Post-cutover monitoring | 1-2 hours | No |
| Full stabilization | 24-48 hours | No |

*Depends on database size

**Total Downtime**: 15-30 minutes

## References

- [CloudNativePG Import Documentation](https://cloudnative-pg.io/documentation/current/bootstrap/#import-existing-databases)
- [PostgreSQL pg_dump Documentation](https://www.postgresql.org/docs/current/app-pgdump.html)
- [PostgreSQL pg_restore Documentation](https://www.postgresql.org/docs/current/app-pgrestore.html)
- [Zalando Postgres Operator](https://github.com/zalando/postgres-operator)
- [Mastodon Database Requirements](https://docs.joinmastodon.org/admin/prerequisites/#postgresql)

## Support

For issues during migration:
1. Check troubleshooting section above
2. Review CloudNativePG operator logs: `kubectl logs -n cnpg-system -l app.kubernetes.io/name=cloudnative-pg`
3. Consult CloudNativePG community: https://cloudnative-pg.io/community/
4. Escalate to infrastructure team with collected logs

---

**Migration prepared by**: Infrastructure Team
**Last updated**: {{ date }}
**Status**: Ready for execution

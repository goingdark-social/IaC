---
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: database-cnpg
spec:
  instances: 1
  imageName: ghcr.io/cloudnative-pg/postgresql:17.5
  enablePDB: true
  priorityClassName: mastodon-critical
  managed:
    roles:
      - name: app
        ensure: present
        login: true
        passwordSecret:
          name: database-cnpg-app
        inRoles:
          - pg_read_all_data
          - pg_write_all_data
  #--------------------------------------------#
  # RECOVERY ONLY
  #--------------------------------------------#
  # Bootstrap from backup with point-in-time recovery
  # ONLY used during disaster recovery - remove after cluster is restored
  bootstrap:
    recovery:
      source: backup-source
      recoveryTarget:
        targetTime: "2025-12-15 14:00:00+00"
        targetTLI: "4"
  
  # Reference to backup source for recovery
  # ONLY used during disaster recovery - remove after cluster is restored
  externalClusters:
    - name: backup-source
      plugin:
        name: barman-cloud.cloudnative-pg.io
        parameters:
          barmanObjectName: database-backup
          serverName: database-cnpg
  #--------------------------------------------#
  # RECOVERY ONLY
  #--------------------------------------------#
  storage:
    size: 30Gi
    storageClass: hcloud-volumes-encrypted-xfs
  walStorage:
    size: 10Gi
    storageClass: hcloud-volumes-encrypted-xfs
  plugins:
    - name: barman-cloud.cloudnative-pg.io
      isWALArchiver: true
      parameters:
        barmanObjectName: database-backup
        serverName: database-cnpg-2  # Write to separate path during recovery

  monitoring:
    enablePodMonitor: false
  postgresql:
    parameters:
      ssl_min_protocol_version: "TLSv1.3"
      ssl_max_protocol_version: "TLSv1.3"
      max_connections: "300"
      shared_buffers: "512MB"
      effective_cache_size: "512MB"
      maintenance_work_mem: "128MB"
      checkpoint_completion_target: "0.9"
      wal_buffers: "16MB"
      default_statistics_target: "100"
      random_page_cost: "1.1"
      effective_io_concurrency: "100"
      work_mem: "1702kB"
      huge_pages: "off"
      min_wal_size: "2GB"
      max_wal_size: "8GB"
      max_worker_processes: "4"
      max_parallel_workers_per_gather: "2"
      max_parallel_workers: "4"
      max_parallel_maintenance_workers: "2"
      pg_stat_statements.max: "10000"
      pg_stat_statements.track: "all"
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "1Gi"
  affinity:
    enablePodAntiAffinity: true
    topologyKey: kubernetes.io/hostname
---
apiVersion: postgresql.cnpg.io/v1
kind: Pooler
metadata:
  name: database-cnpg-pooler-rw
spec:
  cluster:
    name: database-cnpg
  instances: 1
  type: rw
  pgbouncer:
    poolMode: transaction
    parameters:
      max_client_conn: "1000"
      default_pool_size: "125"
  template:
    metadata:
      labels:
        app: database-cnpg-pooler-rw
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: kubernetes.io/os
                    operator: Exists  # Match all nodes with OS label (all nodes have this)
      containers:
        - resources:
            requests:
              cpu: 10m
              memory: 100Mi
            limits:
              memory: 100Mi
          name: pgbouncer
      tolerations:
        - key: "autoscaler-node"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
---
apiVersion: postgresql.cnpg.io/v1
kind: Pooler
metadata:
  name: database-cnpg-pooler-ro
spec:
  cluster:
    name: database-cnpg
  instances: 1
  type: ro
  pgbouncer:
    poolMode: transaction
    parameters:
      max_client_conn: "1000"
      default_pool_size: "125"
  template:
    metadata:
      labels:
        app: database-cnpg-pooler-ro
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: kubernetes.io/os
                    operator: Exists  # Match all nodes with OS label (all nodes have this)
      containers:
        - resources:
            requests:
              cpu: 10m
              memory: 100Mi
            limits:
              memory: 100Mi
          name: pgbouncer
      tolerations:
        - key: "autoscaler-node"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
